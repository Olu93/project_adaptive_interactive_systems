\documentclass[11pt,a4paper,oneside]{article}

\title{\textbf{Route2Dam: Provide information on day trips to Rotterdam for students at Utrecht University}}
\date{\today}
\author{Olusanmi Hundogan}
% \pagenumbering{gobble}
\pagenumbering{arabic}

\usepackage{eurosym}
\usepackage{hyperref}
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabularx,booktabs}
\usepackage{multicol}
\usepackage{array}
\usepackage{float}
\usepackage[english]{babel}
\usepackage{quoting}
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{subfiles}
\usepackage{ragged2e}
\usepackage{lmodern,textcomp}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{titling}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
\usepackage[backend=biber, sorting=none]{biblatex}
\usepackage[total={6.5in, 10in}]{geometry}
\addbibresource{references.bib}
\usepackage{parskip}
% \setlength{\parindent}{15pt}
\setlength{\parskip}{0em}

\begin{document}

\maketitle

\section{Route2Dam - A probablistic group travel recommender system}
This paper will provide a layered evaluation for Route2Dam, a group travel recommender system for Utrecht University students that want to visit the city of Rotterdam. The system uses Gaussian processes (GP) and pairwise comparisons as a model-based approach to elicit preferences. The preferences are used to construct individual and aggregated group recommendations. Furthermore, the system will adapt its recommendation on-site based on contextual aspects like time, location, and weather. For a better understanding, the knowledge about Route2Dam and the layered evaluation approach is a prerequisite. The paper will not explain any details of the inner-workings.

\section{The whole system - Goals and Quality Aspects}
In order to sufficiently evaluate a system and identify important quality aspects it is first important to understand the system's goals. Those can vary significantly as main reasons for conducting a city trip include the desire to experience different lifestyles, escaping the current environment or seeing and attending new places and events.\cite{rita2019millennials} Though, being heterogeneous at first glance, the goals are all connected by the desire for diversity. And subsequently the individual desire to discover new content, from which we can derive the first quality aspects -- \textbf{novelty, diversity and serendipity}. More specifically, the system will have to incorporate mechanisms to provide the user with activity recommendations that vary from another and that are not perceived as \emph{already experienced} by the user. In contrast, striving only for these quality aspects does not suffice either, as their consequence lead to blindly recommending random items. Hence, we also need to take the user's preferences into account. Leading to questions about the user's \textbf{satisfaction} and what constitutes them. Aside from user satisfaction, quality aspects such as \textbf{effectiveness, efficiency and usability} play a vital role to reinforce user satisfaction.\cite{CITE} With regards to Route2Dam, we would have to ask how effective the system is in recommending activities, that the user ended up liking; how efficient it can use a minimum amount of user signals such as the profile setup or the pairwise comparisons to generate an effective list of recommendations; and whether simplifications like showing two alternatives at a time or having a one-page profile setup increase the usability of the system? 

With regards to multi-user interactions, these factors also play an important role, albeit in different ways, and are additionally accompanied by notions of fairness and misery.\cite{CITE-Jameson} In this setting the systems goal is to maintain the group's overall pleasure from interaction while keeping individual desires in mind.\cite{CITE} Criteria that are associated with discovery\footnote{Novelty, diversity and serendipity.}, play a secondary role.\cite{CITE-COMPLACENCY-IN-GROUPs} As a result, we now have to substitute the individual with the group and ask whether the sum of their profiles and comparison signals leads to satisfying, and therefore effective, group recommendations. This distinction is important as an individual will change his perceived content with alternatives in a group context.\cite{asch_OpinionsSocialPressure_1955} The efficiency criterion is unaffected by the group context as it translates without changes to groups. In other words, we do not need additional information about the group as a whole to determine the efficiency of the system. By contrast, for usability it is important to understand that the usability for a user to generate an individual ranking does not have to align with the efforts of a group to conduct a city-trip. Fairness and misery are inherently linked and can effect the groups overall satisfaction.\cite{CITE} The system also needs to avoid being perceived as unfair for individuals; especially, if those individuals play a significant role for the group's dynamic.\footnote{No one wants a grumpy group leader or a clown who is too cynical.\cite{CITE}}       

Having established important quality aspects from the individual and collective perspective, we have to understand in which form they are present in Route2Dam. Starting with novelty, diversity and serendipity, the probabilistic approach of the system helps facilitate selecting items for recommendations based on likelihood and not absolute certainty. Meaning, that the system does not return the same results repeatedly, but samples them from a probability distribution. The sampling approach provides room for novel items to be recommended and depends mostly on the variance of the distribution. "Variance" even grants users opportunities to actively control the coverage of items to be recommended. All that, while maintaining a reasonable estimation for the user's preferences characterized by the mean of the distribution. However, as mentioned earlier, it would not suffice to focus on individual satisfaction as group dynamics influence group satisfaction.\cite{CITE} Here, the system tries to achieve group satisfaction by aggregating the individual user preferences into one group preference with the borda rule.\footnote{Another approach would be to estimate the group's preference independently, but that requires different modelling assumptions.\cite{CITE} The approach used in Route2Dam assumes that collective satisfaction consists at least in part of individual satisfaction.} The borda rule has proven to be effective, if XXX, as shown by XXX.\cite{CITE}

Having establisehed the importance of certain quality aspects for group travel recommender systems and pointing out how Route2Dam's approach, we can discuss the metrics that can capture each of the aspects. 
For discovery related aspects, we have to turn to coverage or more specifically \emph{item coverage} as \emph{user coverage} cancels out during the aggregation stage. The percentage of items recommended over all users in the system suffices. \citeauthor{CITE-Shani} suggests to weight the percentage by the activities popularity to avoid ignoring high profile sights. For a more nuanced evaluation we can follow examples by \citeauthor{CITE-Shani} for novelty, diversity and serendipity. Novelty can be measured offline by segmenting all activities into activity classes and computing the entropy of each class being in the set of top-K recommendations conditioned by the user. Serendipty, as deviation from a "natural" prediction, is inherently an online metric. However, in opposition to \citeauthor{Shani}, we do not have to inject unlikely activities into individual rankings. Instead, we can follow which activities the group visits, that deviate from an individuals "natural" preference and observe the subsequent rating. Diversity is a trivial measure, as we can exploit the average activity-activity distances in the top-K recommendations of the user and average over all users. Effectiveness and efficiency can be measured offline and online by the ratio of visited activities and activities that were accessible weighted by the amount of pairwise comparisons required. We have to emphasize accessibility because some activities are temporally or spatially costly and make other activities in the recommendation impossible if chosen. The weighting strongly resembles \citeauthor{CITE-Shani}'s notion of adaptivity. Usability is hard to measure with a proxy, and has therefore traditionally be measured directly in user studies. However, we would first have to question the individual user and then ask the group as a whole.


\section{Beyond metrics - Considerations for Ethics and Privacy}
When it comes to privacy, we again have two examine two dimensions for Route2Dam. First, privacy with regards to the collection of user data and its utilization. Second, privacy with regards to the individual in conjunction with the collective. 

In the former case, we have to look at personal information which directly or indirectly identifies people according to GDPR. The profile data collected during sign-up is an obvious case. Hence, it requires special protection and a dedicated permission by the user to be collected. Not obvious at first glance but still highly sensitive is GPS data. Route2Dam uses the location to make context-aware adaptions. It is fair to assume that the user will place the benefits above privacy concerns, given the purpose of the application as adaptive travel recommender. Yet, the application should still disclose usage beyond obvious uses, such as using it for the user profile or analytical purposes. This is not the case for Route2Dam. The user's history is saved in the form of activities rather than GPS locations. Furthermore, during the actual trip Route2Dam utilizes only the trip creator's location as proxy for the group. The application has no use to store this information only.

The second case focuses more on social group dynamics and influences like fear of losing reputation and group pressure.\cite{CITE-ASCH} Issues at hand are the individual's desire to choose without pressure, the groups desire to maintain harmony and the obligation to hide an individual's preferences against any other member of the group. The last issue may even be detrimental to the former, as negotiation theory tells us that finding consensus in multi-party settings without access to preferences becomes significantly harder.\cite{CITE} Route2Dam handles these issues by proposing a consensus-based option with the option to anonymously disagree. In the case of a disagreement, the decision process switches to approval voting. As a result, the group can come to conclusions without disclosing any personal preferences.  

For ethical considerations, we have to take a step a back by disregarding the goals for individuals and groups. We would have to question whether characteristics of the system are worth accounting for, to additional gain precision. However, as the applications purpose is mostly uncontroversial, we have to take a closer look on the data that is gathered. Specifically, the distinction between Dutch and internationals and the affiliation with the study program. Both give leeway to stereotyping users and are heavily based on simplifying assumptions. Namely, that Dutch students have different preferences from all foreigners; that foreigners are a homogenous group; And that students following a study program have same interests.  

In Route2Dam the study affiliation case is mitigated by the fact that only the faculty is queried. However, the cultural background case requires evaluating whether users and experts perceive the it as either unnecessarily divisive y or too broadly defined.

\section{Layered Evaluation - Dissecting layers \& quality aspects}
In Route2Dam all layers are present to varying degrees. This section will provide a simple overview of how they are realised in Route2Dam, their quality criteria and their importance for the whole system.\\ 
\textbf{CID:} The collection of input data happens on three occasions in the form the collection of user data upon sign-up, the collection of pairwise-comparison results and the gathering of context relevant information\footnote{time, location and weather} on-site. For location we have to make sure that the \emph{accuracy} is as high as possible. \citeauthor{CITE-GPS-GOV}\parencite[as cited in]{CITE-Diggelen} explains that GPS data depends on multiple factors like device-specific hardware capabilities, satellite geometry, signal quality and atmospheric conditions. As a result, it is important to ensure the accuracy for smartphones.\cite{CITE-GPS-GOV} If we turn to user data, we can question correctness upon sign-up. Users might lie during sign-up to hasten the process or because of privacy concerns.\cite{CITE} Finally, comparison results for individuals should display \emph{consistency}, as dictated by utility theory.\cite{CITE} However, literature also says, we can expect inconsistencies;\cite{CITE-Stanford} We only need to know how often they occur and how robust the algorithm is against them. Measuring inconsistency amounts to counting the cycles in a preference-relation graph for a user and averaging over all users. With an ROC-like curve we can quickly see how much inconsistencies the model can take.\\
\textbf{ID:} After discussing the data collection process, we can move on to interpretations. Here, validity is another quality aspect for location because Route2Dam interprets incoming location data as current group position. However, Route2Dam chooses to only use the group admin's location as a stand-in for the whole group. Location changes are interpreted as group transitions to other locations and stagnation as sign for visiting an activity unless no activity is in the area. In these case, we assume the group is taking a break. The whole inference loses its validity in cases, in which the admin departs from the group.\footnote{This also holds for averaging the group's locations. Like in cases where the group decides to split and pursue two activities simultaneously. One could make the case for more robust mode-related location estimations, but that would undermine the idea to maintain as much privacy as possible.} Weather- and time-related adaptions depend on location too. Otherwise, neither would Route2Dam be able to receive an accurate weather status, nor would it be able to compute the feasibility of visiting an activity within its opening hours. Weather, however, adds another layer of uncertainty, because weather conditions are known to be hard to predict. Hence, the accuracy for predicting the right weather is important and depends mostly on the reliability of weather prediction providers. For pairwise comparisons queries, there is little reason to doubt the interpretation, unless the interface or explanations are confusing the user. \\
\textbf{MW:} For this phase, we have to question whether the gaussian process model reflects the reality of the user's preferences. This question places an emphasis on the scrutability of rankings. However, first we have to raise additional questions about the validity of user and item representations as basic inputs for the model. Simply, do the user features successfully represent a user type and do the chosen item features capture every relevant idiosyncrasy of an activity. Without valid representations, we cannot expect correct individual rankings form the GP. Apart from individual rankings we can also ask whether the group rankings successfully model the group's preference. However, social choice literature suggests, that borda indeed captures notions of group preferences.\cite{CITE} As a result, it becomes more important to construct valid individual rankings that form the basis for group rankings.\footnote{One could additionally oppose the validity of connecting pairwise comparisons with utility functions, but per definition utility maps directly onto preference relations.\cite{CITE} In simple terms, if we had a complete and consistent set of comparisons, we could always construct a utility function and vice versa. So no need to question that. The challenge arises from doing the construction with incomplete data sets. A step further, questioning whether functions can capture human preferences in the first place, leads into entirely different scientific disciplines like philosophy of math, psychometrics or game theory.}\\  
\textbf{DA:} Moving on to the next phase, we can identify the breadth of experience of individual users and the subjective acceptance of recommendations as most important criteria. If we think about the necessity and appropriateness of adaptations, we have to admit that recommending activities naturally requires adaptations.\cite{CITE} Especially, when it comes to weather and time-related adaptations for the group.\footnote{As individual necessity and appropriateness are highly subjective, but groups may show way higher sensitivity to context-changes.\cite{CITE} Also, location and user data were excluded because groups might decide to willingly dismiss recommended adaptations.} A storm should always change the beach recommendation and midnight-Rotterdam-visits simply cannot include a brunch. So necessity and appropriateness are not very important. Same holds for predictability and scrutability, as it is hard to achieve it with probabilistic approaches. As a result, subjective acceptance becomes even more important. Mainly, because ultimately the group decides on activities and that entails group dynamics that are too complex to predict. Breadth of experience in terms of visited activities only matters, because an individual's goal might be discovery related. Repeatedly notifying the group about the same must-see's undermines this goal. Both, subjective acceptance and experience, can be examined using the group's and user's history of visited activities. Here, we can determine the performance by: Counting false-positives, e.g. notifications the group ignored. And by taking the ratio of notifications and their appearances in a users activitiy history.\\
\\
\textbf{AD:} The last phase, will have to be evaluated on the usability and timeliness of on-site notifications and the acceptance of context-adapted activities. Other adaptations only happen after user input but not without user interaction. Using notifications to inform the group about must-see activities in the vicinity naturally seems timely if we consider the groups current location, the time and the vicinity. However, we can question the amount of notifications and whether the selected must-see attractions are relevant for the group in the first place. As edge case, a group located in the vicinity of multiple must-see attractions but consisting of users who know Rotterdam already and thus, show little interest in seeing must-see attractions. This might not affect usability directly but might obstruct the perception of timeliness. Again counting false-positives seems appropriate. Usability is highly subjective for individuals and collectives. So, we would have to consult a user test to investigate this criterion and there's no clear metric other than a user rating. 

After inspecting all layers, we will focus on ID and MW. On one hand, the reason for ID follows the dependence between the validity of group locations and context-related adaptions like time and weather and on the other hand, the importance of its interpretations for accurate predictions in MW. The MW phase's importance stems from the use of a model-based approach to predict the individual rankings. Without a good model, we cannot expect Route2Dam to satisfy each individual, which also weakens the collective's satisfaction.\cite{CITE} Simply put, an unsuccessful model would likely violate both application goals.    

\section{ID \& MW - Examining Specification, Design \& Implementation}

\subsection{ID - Questioning the foundations of interpretations}
\textbf{Specification:} In this phase, we require location, counts and reasons for splitting for touristic groups. With a simple field survey we can estimate the average accuracy of the location and discern the significance for group splitting. It should be noted that we would also have to track the group's size, as the splitting probability might depend on it. To confirm the validity of weather, we need to data mine the accuracies of weather predictions of different weather providers and compare them with actual weather conditions. In both cases, we resort to data analytics, because statistical metrics are easy to collect and interpret.\\ 
\textbf{Design:} Here, we can question whether GPS data translates to group data. We can use a heuristic evaluation and ask experts for the plausibility of GPS tracked data. We need experts rather than regular users, because the judgement involves incorporating domain-specific knowledge about Rotterdam, activity durations and urban mobility.\footnote{In the Netherlands, a group might choose different modes of transportation. Walking, public transport or bikes have very different speeds.\cite{CITE} This obviously changes the travel speed.} The experts should be urban planners and infrastructure officials. They will receive a group segmented set of time points and location data. With this information, they shall discern the plausibility of breaks, visits or transitions.  \\
\textbf{Implementation:} With group-splitting-chance, weather-likelihood and location plausibility, it is possible to run a decisive user test by instructing groups of friends to visit Rotterdam and frequently track location, time, current activity and group splits. We can compare the results with the estimations, we have gathered so far and update them. Here, the user-centric approach promises more realistic results than data related techniques.

\subsection{MW - Validating the model's world-view}
\textbf{Specification:} During the specification phase, we can focus on groups and ask what characteristics influence a student's preference.\cite{CITE} Here, it is important to ask a balanced group consisting of students and non-students. The expected output would result in a list of user characteristics. The focus group would also be asked about the current activity representation. From a focus group, we would not only gain ideas for more features but also hints about their perceived irrelevance and relevance.\\
\textbf{Design:} A mock-up and core algorithms simplifies the validation of user- and item representations. Now, we can use statistics to validate user representations by computing the correlation between features and pairwise-comparison results. Item similarities can be verified by manually inspecting clusters using techniques like K-means. A focus group of experts may attest proper separation confirming the validity of item similarities. For the GP, we can rely on the scrutiny of users as wizards.\cite{CITE} Here, comparability with the GP is important. We have to provide users with the same input. Namely, a set of users and their pairwise-comparison results for activity pairs. However, the system uses feature vectors representations, which are difficult to grasp. With regards to activities, we can simply overcome this issue by using images and short activity descriptions. For users, we would have to translate the user vector into natural language. As an illustration, we consider a user vector $u = \left(\begin{smallmatrix} 1, & 0, & 60, & 9, & 3, & 0 \end{smallmatrix}\right)$. The features refer to cultural background, Rotterdam first-timer, budget, how often he preferred the museum activity type, the bar activity type and the shopping activity type. We can translate this vector into \emph{"Peter is a foreigner, never went to Rotterdam before and has a budget of around 60â‚¬. He typically enjoys museums the most, but sometimes he would also visit a bar. He does not like shopping activities at all."} The natural language generation literature is a helpful framework to construct profiles, which sound more natural and show more variation.\cite{CITE} With these profile descriptions and the pairwise comparisons, we can instruct users to \emph{"think thoroughly about an appropriate activity-ranking according to each individual's preference. The list should start with the most preferred as first element."}\\
\textbf{Implementation:} 
The implementation phase enables us to use fast evaluation approaches like cross-validation. However, this requires collecting a gold-set of users and their preference rankings. Initially, we can use the MW output of the Design phase, but eventually, for more accurate results, it will become necessary to survey visitors of Rotterdam. Here, we would have to query for user characteristics according to the feature vector, pairwise preference comparisons and independently a ranking of activities. At this point several issues come into mind: First, the amount of necessary comparisons is $n^2$ with $n$ being the number of activities. Second, the cognitive burden of ranking items also increases with $n$. As a result, it becomes necessary to choose a subset, which reduces the accuracy of the gold-set. A meaningful reduction-strategy such as choosing representative activities per category might account for that. We can reuse the clustering results from the design phase to find valid representatives. With this setting, the best case would show consistent comparisons that also align with the ranking. However, although the GP model can account for inconsistent comparison, deviating rankings cannot be avoided. Simply put, unless the GP overfits, there is an upper bound to to most metrics, if the data is mislabelled. Yet, the value at least provides a quantifiable guide for improvements. As metric we can use mean average precision (MAP).\cite{CITE} This metric is rank aware as it penalizes higher ranked errors more and does not depend on numerical values. In fact, because it uses set intersections it is inherently order-invariant. Although, often seen as flaw, this property mitigates the concerns about inconsistent rankings. To put it differently, as we cannot expect the correct order of user rankings within the gold-set, the mere prediction of relevant items becomes more important.  
% You and your best friends Beth, Sam, Sarah and Jaime visit Rotterdam together. After seeing some places, you and Beth prefer visiting a museum. Sam, Sarah and Jaime want to see the Erasmus bridge. Due to time constraints you cant do both. Which solution would you prefer? Museum, Erasmus bridge or splitting the group? 
\clearpage 
\printbibliography
\end{document}